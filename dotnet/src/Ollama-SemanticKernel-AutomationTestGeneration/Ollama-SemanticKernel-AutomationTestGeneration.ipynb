{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Ollama-SemanticKernel Automation Test Generation ğŸ¤–\n",
    "\n",
    "Welcome to this exciting journey of AI-powered test automation! ğŸ‰ This notebook demonstrates how to leverage the power of Ollama and Semantic Kernel to automatically generate C# Playwright page object models. Let's revolutionize the way we create automation tests! ğŸ’ª\n",
    "\n",
    "## ğŸŒŸ What We'll Accomplish\n",
    "\n",
    "1. ğŸ”§ Set up our environment with necessary packages\n",
    "2. ğŸ§  Configure Ollama and Semantic Kernel\n",
    "3. ğŸ“ Load and process prompt templates\n",
    "4. ğŸ­ Generate C# Playwright page object models from natural language descriptions\n",
    "5. ğŸ” Explore the generated code and understand its structure\n",
    "\n",
    "## ğŸ› ï¸ Technologies Used\n",
    "\n",
    "- ğŸ¦™ Ollama: For running large language models locally\n",
    "- ğŸ§  Semantic Kernel: Microsoft's framework for AI orchestration\n",
    "- ğŸ­ Playwright: For web testing and automation\n",
    "- ğŸ”· C#: Our primary programming language\n",
    "\n",
    "## ğŸ’¡ Key Concepts\n",
    "\n",
    "- Few-shot learning: Using examples to guide AI output\n",
    "- Prompt engineering: Crafting effective instructions for AI models\n",
    "- Page Object Model: A design pattern for creating maintainable automation tests\n",
    "\n",
    "Ready to dive in? Let's start coding and see AI in action! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“¦ NuGet Package Installation\n",
    "\n",
    "This cell sets up our development environment by installing the necessary NuGet packages for our project.\n",
    "\n",
    "- **Microsoft.SemanticKernel**: This package provides the core functionality for building AI-powered applications. It allows us to integrate large language models (LLMs) into our C# code seamlessly.\n",
    "\n",
    "- **OllamaSharp**: This package is a C# client for Ollama, enabling us to interact with Ollama's API and leverage its capabilities in our project.\n",
    "\n",
    "By running this cell, we ensure that our notebook has access to all the required dependencies for generating C# Playwright page object models using AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.17.1</span></li><li><span>OllamaSharp, 2.1.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.SemanticKernel\"\n",
    "#r \"nuget:OllamaSharp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Importing Necessary Namespaces\n",
    "\n",
    "This cell imports all the required namespaces for our project. Let's break down why each is important:\n",
    "\n",
    "## ğŸ”§ System Namespaces\n",
    "- `System`: Provides fundamental classes and base classes for C#\n",
    "- `System.IO`: Enables reading and writing to files and data streams\n",
    "- `System.Net.Http`: Allows making HTTP requests, crucial for API interactions\n",
    "- `System.Threading`: Provides classes for multi-threaded programming\n",
    "\n",
    "## ğŸ¦™ Ollama Integration\n",
    "- `OllamaSharp`: The main namespace for interacting with Ollama\n",
    "- `OllamaSharp.Models.Chat`: Contains models specific to chat functionalities in Ollama\n",
    "\n",
    "## ğŸ§  Semantic Kernel Setup\n",
    "- `Microsoft.Extensions.DependencyInjection`: For setting up dependency injection\n",
    "- `Microsoft.SemanticKernel`: The core namespace for Semantic Kernel functionality\n",
    "- `Microsoft.SemanticKernel.ChatCompletion`: Specific to chat completion features in Semantic Kernel\n",
    "\n",
    "By importing these namespaces, we're equipping our notebook with all the tools needed to interact with Ollama, utilize Semantic Kernel, and handle various system-level operations. This sets the stage for our AI-powered test generation adventure! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.IO;\n",
    "using System.Net.Http;\n",
    "using System.Threading;\n",
    "\n",
    "using OllamaSharp;\n",
    "using OllamaSharp.Models.Chat;\n",
    "\n",
    "using Microsoft.Extensions.DependencyInjection;\n",
    "\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”§ Configuration Settings\n",
    "\n",
    "This cell defines crucial configuration settings for our AI-powered test generation project. Let's break down each variable:\n",
    "\n",
    "## ğŸ¨ `_outputFormat`\n",
    "- Set to: `\"Handlebars\"`\n",
    "- Purpose: Specifies the template engine used for formatting the AI's output.\n",
    "- ğŸ’¡ Handlebars is a popular templating language that allows for dynamic content insertion.\n",
    "\n",
    "## ğŸ“ `_promptsDirectory`\n",
    "- Path: `\"./resources/prompts/example-input\"`\n",
    "- Purpose: Points to the directory containing example inputs for few-shot learning.\n",
    "- ğŸš€ These examples help guide the AI in generating accurate and relevant code.\n",
    "\n",
    "## ğŸ“˜ `_outputInstructDirectory`\n",
    "- Path: `\"./resources/prompts/output-instruct\"`\n",
    "- Purpose: Specifies the location of output instruction templates.\n",
    "- ğŸ­ These instructions help format the AI's responses consistently.\n",
    "\n",
    "## ğŸ“ `_mainPromptFile`\n",
    "- Path: `\"./resources/prompts/llm.md\"`\n",
    "- Purpose: Indicates the file containing the main system prompt for the AI.\n",
    "- ğŸ§  This prompt sets the context and provides general instructions for the AI.\n",
    "\n",
    "These settings form the backbone of our project's configuration, allowing for easy customization and maintenance. By adjusting these paths, we can quickly adapt our system to use different prompts, examples, or output formats. ğŸ› ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "static string _outputFormat = \"Handlebars\";\n",
    "static string _promptsDirectory = \"./resources/prompts/example-input\";\n",
    "static string _outputInstructDirectory = \"./resources/prompts/output-instruct\";\n",
    "static string _mainPromptFile = \"./resources/prompts/llm.md\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ—ï¸ Implementing Chat Completion Services\n",
    "\n",
    "This cell defines two crucial classes for our AI-powered test generation project: `BaseOllamaChatCompletionService` and `GenericChatCompletionService`. Let's break down their structure and purpose:\n",
    "\n",
    "## ğŸ§± BaseOllamaChatCompletionService\n",
    "\n",
    "This abstract class serves as the foundation for our Ollama-based chat completion services.\n",
    "\n",
    "Key Components:\n",
    "- ğŸŒ `_httpClient`: For making HTTP requests to the Ollama API\n",
    "- ğŸ“› `_modelName`: Stores the name of the language model being used\n",
    "- ğŸ“š `Attributes`: A dictionary for storing additional attributes\n",
    "\n",
    "Main Method:\n",
    "- ğŸ”„ `GetChatMessageContentsAsync`: \n",
    "  - Handles the core chat completion logic\n",
    "  - Manages chat history and system prompts\n",
    "  - Interacts with the Ollama API to generate responses\n",
    "\n",
    "Notable Features:\n",
    "- ğŸ”’ Abstract method `GetSystemPromptAsync`: Allows subclasses to define their own system prompts\n",
    "- ğŸš« `GetStreamingChatMessageContentsAsync`: Placeholder for potential future streaming implementation\n",
    "\n",
    "## ğŸ›ï¸ GenericChatCompletionService\n",
    "\n",
    "This concrete class extends `BaseOllamaChatCompletionService`, providing a simple implementation.\n",
    "\n",
    "Key Features:\n",
    "- ğŸ—ï¸ Constructor: Initializes the service with a model URL and name\n",
    "- ğŸ—¨ï¸ `GetSystemPromptAsync`: Returns a basic system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public abstract class BaseOllamaChatCompletionService : IChatCompletionService\n",
    "{\n",
    "    protected readonly HttpClient _httpClient;\n",
    "    protected readonly string _modelName;\n",
    "    \n",
    "    public IReadOnlyDictionary<string, object?> Attributes { get; set; } = new Dictionary<string, object?>();\n",
    "\n",
    "    /// <summary>\n",
    "    /// Initializes a new instance of the <see cref=\"BaseOllamaChatCompletionService\"/> class.\n",
    "    /// </summary>\n",
    "    /// <param name=\"modelUrl\">The URL of the model.</param>\n",
    "    /// <param name=\"modelName\">The name of the model.</param>\n",
    "    protected BaseOllamaChatCompletionService(string modelUrl, string modelName)\n",
    "    {\n",
    "        _modelName = modelName;\n",
    "        _httpClient = new HttpClient\n",
    "        {\n",
    "            BaseAddress = new Uri(modelUrl),\n",
    "            Timeout = TimeSpan.FromMinutes(2)\n",
    "        };\n",
    "    }\n",
    "\n",
    "\n",
    "    /// <summary>\n",
    "    /// Gets the chat message contents asynchronously.\n",
    "    /// </summary>\n",
    "    /// <param name=\"chatHistory\">The chat history.</param>\n",
    "    /// <param name=\"executionSettings\">The execution settings.</param>\n",
    "    /// <param name=\"kernel\">The kernel.</param>\n",
    "    /// <param name=\"cancellationToken\">The cancellation token.</param>\n",
    "    public virtual async Task<IReadOnlyList<ChatMessageContent>> GetChatMessageContentsAsync(\n",
    "        ChatHistory chatHistory,\n",
    "        PromptExecutionSettings? executionSettings = null,\n",
    "        Kernel? kernel = null,\n",
    "        CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        var ollama = new OllamaApiClient(_httpClient, _modelName);\n",
    "        var chat = new Chat(ollama, _ => { });\n",
    "\n",
    "        // Add system message\n",
    "        var systemPrompt = await GetSystemPromptAsync();\n",
    "        await chat.SendAs(ChatRole.System, systemPrompt, cancellationToken);\n",
    "\n",
    "        // Iterate through chatHistory Messages\n",
    "        foreach (var message in chatHistory)\n",
    "        {\n",
    "            if (message.Role == AuthorRole.System)\n",
    "            {\n",
    "                await chat.SendAs(ChatRole.System, message.Content ?? string.Empty, cancellationToken);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        var lastMessage = chatHistory.LastOrDefault();\n",
    "        string question = lastMessage?.Content ?? string.Empty;\n",
    "        var history = (await chat.Send(question, cancellationToken)).ToArray();\n",
    "        var chatResponse = history.Last().Content ?? string.Empty;\n",
    "\n",
    "        chatHistory.AddAssistantMessage(chatResponse);\n",
    "\n",
    "        return chatHistory;\n",
    "    }\n",
    "\n",
    "    /// <summary>\n",
    "    /// Gets the streaming chat message contents asynchronously.\n",
    "    /// </summary>\n",
    "    /// <param name=\"chatHistory\">The chat history.</param>\n",
    "    /// <param name=\"executionSettings\">The execution settings.</param>\n",
    "    /// <param name=\"kernel\">The kernel.</param>\n",
    "    /// <param name=\"cancellationToken\">The cancellation token.</param>\n",
    "    public virtual IAsyncEnumerable<StreamingChatMessageContent> GetStreamingChatMessageContentsAsync(\n",
    "        ChatHistory chatHistory,\n",
    "        PromptExecutionSettings? executionSettings = null,\n",
    "        Kernel? kernel = null,\n",
    "        CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        throw new NotImplementedException();\n",
    "    }\n",
    "\n",
    "    protected abstract Task<string> GetSystemPromptAsync();\n",
    "}\n",
    "\n",
    "public class GenericChatCompletionService : BaseOllamaChatCompletionService\n",
    "{\n",
    "    /// <summary>\n",
    "    /// Initializes a new instance of the <see cref=\"GenericChatCompletionService\"/> class.\n",
    "    /// </summary>\n",
    "    /// <param name=\"modelUrl\">The URL of the model.</param>\n",
    "    /// <param name=\"modelName\">The name of the model.</param>\n",
    "    public GenericChatCompletionService(string modelUrl, string modelName) : base(modelUrl, modelName)\n",
    "    {\n",
    "\n",
    "    }\n",
    "\n",
    "    /// <summary>\n",
    "    /// Gets the system prompt asynchronously.\n",
    "    /// </summary>\n",
    "    /// <returns>The system prompt.</returns>\n",
    "    protected override Task<string> GetSystemPromptAsync()\n",
    "    {\n",
    "        return Task.FromResult(\"You are a helpful assistant.\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ PromptEngine: Powering Our AI's Understanding\n",
    "\n",
    "The `PromptEngine` class is the heart of our (very simple) prompt management system. It handles loading, combining, and formatting the various components that guide our AI in generating accurate C# Playwright page object models. Let's break it down:\n",
    "\n",
    "## ğŸ§  Key Methods\n",
    "\n",
    "### 1. ğŸ“š `LoadExamplesFromFilesAsync`\n",
    "- ğŸ¯ Purpose: Loads example prompts from markdown files\n",
    "- ğŸ“‚ Source: `_promptsDirectory`\n",
    "- ğŸ”¢ Limit: Controlled by `maxExamples` parameter\n",
    "- ğŸ” Note: Helps in implementing few-shot learning\n",
    "\n",
    "### 2. ğŸ“˜ `LoadOutputInstructionsAsync`\n",
    "- ğŸ¯ Purpose: Loads instructions for formatting the AI's output\n",
    "- ğŸ“‚ Source: `_outputInstructDirectory`\n",
    "- ğŸ¨ Format: Determined by `_outputFormat` (e.g., Handlebars)\n",
    "\n",
    "### 3. ğŸ“ `LoadMainPromptAsync`\n",
    "- ğŸ¯ Purpose: Loads the main system prompt\n",
    "- ğŸ“‚ Source: `_mainPromptFile`\n",
    "- âš ï¸ Note: Throws an exception if the file is not found\n",
    "\n",
    "### 4. ğŸ”§ `GetSystemPromptWithExamplesAsync`\n",
    "- ğŸ¯ Purpose: Combines all components into a single, formatted prompt\n",
    "- ğŸ§© Components: Main prompt, examples, output format, and instructions\n",
    "- ğŸ”¢ Default: Loads up to 3 examples unless specified otherwise\n",
    "\n",
    "The `PromptEngine` ensures that our AI receives well-structured, consistent instructions, enhancing the quality and reliability of the generated C# Playwright page object models. It's the bridge between our project's configuration and the AI's understanding of its task. ğŸŒ‰ğŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "/// <summary>\n",
    "/// Simple prompt engine.\n",
    "/// </summary>\n",
    "public static class PromptEngine{\n",
    "    /// <summary>\n",
    "    /// Loads the examples from files asynchronously.\n",
    "    /// </summary>\n",
    "    /// <param name=\"maxExamples\">The maximum number of examples to load.</param>\n",
    "    /// <returns>The examples.</returns>\n",
    "    public static async Task<string> LoadExamplesFromFilesAsync(int maxExamples)\n",
    "    {\n",
    "        var exampleFiles = Directory.GetFiles(_promptsDirectory, \"*.md\");\n",
    "        var examples = new StringBuilder();\n",
    "\n",
    "        var idx = 0;\n",
    "\n",
    "        foreach (var file in exampleFiles)\n",
    "        {\n",
    "            if(idx >= maxExamples)\n",
    "            {\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            examples.AppendLine($\"Example: {Path.GetFileNameWithoutExtension(file)}\");\n",
    "            examples.AppendLine(await File.ReadAllTextAsync(file));\n",
    "            examples.AppendLine();\n",
    "\n",
    "            idx++;\n",
    "        }\n",
    "\n",
    "        return examples.ToString();\n",
    "    }\n",
    "\n",
    "    /// <summary>\n",
    "    /// Loads the output instructions asynchronously.\n",
    "    /// </summary>\n",
    "    /// <returns>The output instructions.</returns> \n",
    "    public static async Task<string> LoadOutputInstructionsAsync()\n",
    "    {\n",
    "        var instructionFile = Path.Combine(_outputInstructDirectory, $\"{_outputFormat}.md\");\n",
    "        if (File.Exists(instructionFile))\n",
    "        {\n",
    "            return await File.ReadAllTextAsync(instructionFile);\n",
    "        }\n",
    "        return string.Empty;\n",
    "    }\n",
    "\n",
    "    /// <summary>\n",
    "    /// Loads the main prompt asynchronously.\n",
    "    /// </summary>\n",
    "    /// <returns>The main prompt.</returns>\n",
    "    public static async Task<string> LoadMainPromptAsync()\n",
    "    {\n",
    "        if (File.Exists(_mainPromptFile))\n",
    "        {\n",
    "            return await File.ReadAllTextAsync(_mainPromptFile);\n",
    "        }\n",
    "        throw new FileNotFoundException($\"Main prompt file not found: {_mainPromptFile}\");\n",
    "    }\n",
    "\n",
    "    /// <summary>\n",
    "    /// Gets the system prompt with examples asynchronously.\n",
    "    /// </summary>\n",
    "    /// <param name=\"maxExamples\">The maximum number of examples to load.</param>\n",
    "    /// <returns>The system prompt with examples.</returns>\n",
    "    public static async Task<string> GetSystemPromptWithExamplesAsync(int maxExamples = 3)\n",
    "    {\n",
    "        var mainPrompt = await LoadMainPromptAsync();\n",
    "        var examples = await LoadExamplesFromFilesAsync(maxExamples);\n",
    "        var outputInstructions = await LoadOutputInstructionsAsync();\n",
    "\n",
    "        return string.Format(mainPrompt, examples, _outputFormat, outputInstructions);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ­ Generating C# Playwright Page Object Models\n",
    "\n",
    "This cell showcases the culmination of our project: using AI to generate C# Playwright page object models. Let's break down the process and examine the result.\n",
    "\n",
    "## ğŸš€ The Generation Process\n",
    "\n",
    "1. ğŸ“ **Loading Prompts**\n",
    "   - Reads all prompt files from `./resources/prompts/models`\n",
    "   - Each file likely contains a description of a web page or component\n",
    "\n",
    "2. ğŸ§  **Preparing the System Prompt**\n",
    "   - Uses `PromptEngine.GetSystemPromptWithExamplesAsync()` to create a comprehensive prompt\n",
    "   - Includes examples and instructions for the AI\n",
    "\n",
    "3. ğŸ¤– **Setting Up Ollama**\n",
    "   - Creates a `GenericChatCompletionService` connected to a local Ollama instance\n",
    "   - Uses the \"llama3\" model\n",
    "\n",
    "4. ğŸ”§ **Configuring Semantic Kernel**\n",
    "   - Sets up a `Kernel` with the Ollama chat service\n",
    "\n",
    "5. ğŸ” **Processing Each Prompt**\n",
    "   - Iterates through each loaded prompt\n",
    "   - Creates a new `ChatHistory` for each prompt\n",
    "   - Adds the system prompt and user input to the history\n",
    "   - Generates a response using the chat service\n",
    "\n",
    "6. ğŸ“¤ **Output**\n",
    "   - Prints the generated C# code to the console\n",
    "\n",
    "## ğŸ¨ The Generated Page Object Model\n",
    "\n",
    "The AI has produced a `ShoppingCartPage` class, which is a comprehensive Playwright page object model. Key features include:\n",
    "\n",
    "- ğŸ“¦ **Base Structure**: Inherits from `BasePage` and uses Playwright's `IPage`\n",
    "- ğŸ§± **Nested Classes**: `CartItemsList`, `CartItem`, and `CartItems` for structured element representation\n",
    "- ğŸ” **Locators**: Defined for various elements like product name, quantity input, and remove button\n",
    "- ğŸ› ï¸ **Methods**: \n",
    "  - `UpdateItemQuantityAsync`: For changing item quantities\n",
    "  - `RemoveItemAsync`: For removing items from the cart\n",
    "  - `ProceedToCheckoutAsync`: For moving to the checkout process\n",
    "\n",
    "This cell demonstrates the power of AI in automating the creation of test infrastructure, potentially saving hours of manual coding and reducing errors in the process. ğŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Microsoft.Playwright;\n",
      "\n",
      "public class ShoppingCartPage : BasePage\n",
      "{\n",
      "    private readonly IPage _page;\n",
      "\n",
      "    public ShoppingCartPage(IPage page) : base(page)\n",
      "    {\n",
      "        _page = page;\n",
      "    }\n",
      "\n",
      "    public class CartItemsList : BaseElement\n",
      "    {\n",
      "        public CartItemsList(ILocator locator) : base(locator)\n",
      "        {\n",
      "        }\n",
      "\n",
      "        public new async Task<IReadOnlyList<CartItems>> AllAsync()\n",
      "        {\n",
      "            var all = await base.AllAsync();\n",
      "            return all.Select(a => new CartItems(a)).ToList();\n",
      "        }\n",
      "    }\n",
      "\n",
      "    public class CartItem : BaseElement\n",
      "    {\n",
      "        private readonly ILocator _locator;\n",
      "\n",
      "        public CartItem(ILocator locator) : base(locator)\n",
      "        {\n",
      "            _locator = locator;\n",
      "        }\n",
      "\n",
      "        public ILocator ProductName => _locator.Locator(\".product-name\");\n",
      "        public ILocator QuantityInput => _locator.Locator(\".quantity-input\");\n",
      "        public ILocator RemoveButton => _locator.Locator(\".remove-item\");\n",
      "    }\n",
      "\n",
      "    public class CartItems : BaseElement\n",
      "    {\n",
      "        private readonly ILocator _locator;\n",
      "\n",
      "        public CartItems(ILocator locator) : base(locator)\n",
      "        {\n",
      "            _locator = locator;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    public async Task UpdateItemQuantityAsync(string productname, int quantity)\n",
      "    {\n",
      "        await CartItemsList.ClientRows.ProductName.ClickAsync($\"[data-product-name='{productname}']\");\n",
      "        await CartItemsList.ClientRows.QuantityInput.FillAsync(quantity.ToString());\n",
      "    }\n",
      "\n",
      "    public async Task RemoveItemAsync(string productname)\n",
      "    {\n",
      "        await CartItemsList.ClientRows.ProductName.ClickAsync($\"[data-product-name='{productname}']\");\n",
      "        await CartItemsList.ClientRows.RemoveButton.ClickAsync();\n",
      "    }\n",
      "\n",
      "    public async Task ProceedToCheckoutAsync()\n",
      "    {\n",
      "        await CartItemsList.ClientRows.CheckoutButton.ClickAsync();\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "var prompts = Directory.EnumerateFiles(\"./resources/prompts/models\")\n",
    "    .Select(promptFile => File.ReadAllText(promptFile));\n",
    "\n",
    "var sysPrompt = await PromptEngine.GetSystemPromptWithExamplesAsync();\n",
    "\n",
    "// await SolveProblemWithToT(input);\n",
    "var ollamaChat = new GenericChatCompletionService(\"http://localhost:11434\", \"llama3\");\n",
    "\n",
    "var builder = Kernel.CreateBuilder();\n",
    "\n",
    "builder.Services.AddKeyedSingleton<IChatCompletionService>(\"ollamaChat\", ollamaChat);\n",
    "Kernel kernel = builder.Build();\n",
    "\n",
    "\n",
    "foreach(var prompt in prompts){\n",
    "    var chat = kernel.GetRequiredService<IChatCompletionService>();\n",
    "\n",
    "    var history = new ChatHistory();\n",
    "    history.AddSystemMessage(sysPrompt);\n",
    "    history.AddUserMessage(prompt);\n",
    "\n",
    "    var result = await chat.GetChatMessageContentsAsync(history);\n",
    "\n",
    "    Console.WriteLine(result[^1].Content);\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
